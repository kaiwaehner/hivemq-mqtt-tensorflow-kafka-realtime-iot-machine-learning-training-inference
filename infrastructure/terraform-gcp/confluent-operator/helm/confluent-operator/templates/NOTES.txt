{{- if .Values.operator.enabled }}

                                        The Confluent Operator

The Confluent Operator interacts with kubernetes API to create statefulsets resources. The Confluent Operator runs three
controllers, two component specific controllers for kubernetes by providing components specific Custom Resource
Definition (CRD) (for Kafka and Zookeeper) and one controller for creating other statefulsets resources.

{{- if .Values.global.provider.registry.credential.required }}

  - Give the `default` Service Account access to pull images from {{ .Values.global.provider.registry.fqdn }}

  kubectl -n {{ .Release.Namespace }} patch serviceaccount default -p '{"imagePullSecrets": [{"name": "confluent-docker-registry" }]}'
{{- end }}

  1. Validate if Confluent Operator is running.

  kubectl get pods -n {{ .Release.Namespace }} | grep {{ .Values.operator.name }}

  2. Validate if custom resource definition (CRD) is created.

  kubectl get crd | grep confluent

{{- end }}


{{- if .Values.zookeeper.enabled }}

        Zookeeper Cluster Deployment

Zookeeper cluster is deployed through CR.

  0. List of Deprecated Features (if any)
     {{ include "confluent-operator.deprecated-list" .Values.zookeeper }}

  1. Validate if Zookeeper Custom Resource (CR) is created

     kubectl get zookeeper -n {{ .Release.Namespace }} | grep {{ .Values.zookeeper.name }}

  2. Check the status/events of CR: {{ .Values.zookeeper.name }}

     kubectl describe zookeeper {{ .Values.zookeeper.name }} -n {{ .Release.Namespace }}

  3. Check if Zookeeper cluster is Ready

     kubectl get zookeeper {{ .Values.zookeeper.name }} -ojson -n {{ .Release.Namespace }}

     kubectl get zookeeper {{ .Values.zookeeper.name }} -ojsonpath='{.status.phase}' -n {{ .Release.Namespace }}

  4. Update/Upgrade Zookeeper Cluster

     The upgrade can be done either through the helm upgrade or by editing the CR directly as below;

     kubectl edit zookeeper {{ .Values.zookeeper.name }}  -n {{ .Release.Namespace }}

{{- end }}
{{- if .Values.kafka.enabled }}

        Kafka Cluster Deployment

Kafka Cluster is deployed to kubernetes through CR Object

  0. List of Deprecated Features (if any)
   {{ include "confluent-operator.deprecated-list" .Values.kafka }}

  1. Validate if Kafka Custom Resource (CR) is created

     kubectl get kafka -n {{ .Release.Namespace }} | grep {{ .Values.kafka.name }}

  2. Check the status/events of CR: {{ .Values.kafka.name }}

     kubectl describe kafka {{ .Values.kafka.name }} -n {{ .Release.Namespace }}

  3. Check if Kafka cluster is Ready

     kubectl get kafka {{ .Values.kafka.name }} -ojson -n {{ .Release.Namespace }}

     kubectl get kafka {{ .Values.kafka.name }} -ojsonpath='{.status.phase}' -n {{ .Release.Namespace }}

  4.  Broker Listener (Protocol/Port)

      External Listener: kubectl  -n {{ .Release.Namespace }}  get kafka {{ $.Values.kafka.name }} -ojsonpath='{.status.brokerExternalListener}'
      Internal Listener: kubectl  -n {{ .Release.Namespace }}  get kafka {{ $.Values.kafka.name }} -ojsonpath='{.status.brokerInternalListener}'

      Note: If Protocol is SSL, configure truststore (https://docs.confluent.io/current/kafka/encryption.html#clients) and keystore 
        (https://docs.confluent.io/current/kafka/authentication_ssl.html#clients) if client Authentication is enabled (
        kubectl  -n {{ .Release.Namespace }}  get kafka {{ $.Values.kafka.name }} -ojsonpath='{.status.clientAuthentication}' )

  5. Update/Upgrade Kafka Cluster

     The upgrade can be done either through the helm upgrade or by editing the CR directly as below;

     kubectl edit kafka {{ .Values.kafka.name }}  -n {{ .Release.Namespace }}

     Note: Switching Kafka security requires manual restart of all the dependent components as the JAAS configuration changes is required.

  6. All Kafka Information like zookeeper connect, replications factor, isr, Client Jaas Configuration
     and much more can be found on the Status section of CR.

     kubectl get kafka {{ .Values.kafka.name }} -n {{ .Release.Namespace }} -oyaml

  7. Client Access:

     Run below command to validate if Kafka cluster is working.

     1. Get the Client Jaas Information

        {{- if .Values.kafka.loadBalancer.enabled }} 
        External : kubectl  -n {{ .Release.Namespace }}  get kafka {{ $.Values.kafka.name }} -ojsonpath='{.status.externalClient}' > kafka.properties
        {{- end }}
        Internal : kubectl  -n {{ .Release.Namespace }}  get kafka {{ $.Values.kafka.name }} -ojsonpath='{.status.internalClient}' > kafka.properties
     2. To get the Bootstrap endpoint

        kubectl -n {{ .Release.Namespace }} get kafka {{ $.Values.kafka.name }} -ojsonpath='{.status.bootstrapEndpoint}'

     3. To get the Replication Factor

        kubectl -n {{ .Release.Namespace }} get kafka {{ $.Values.kafka.name }} -ojsonpath='{.status.replicationFactor}'

     4. To get the Zookeeper Connect endpoint

        kubectl -n {{ .Release.Namespace }} get kafka {{ $.Values.kafka.name }} -ojsonpath='{.status.zookeeperConnect}'

    {{ if .Values.kafka.loadBalancer.enabled  }}
      External:
          {{- if empty $.Values.kafka.loadBalancer.bootstrapPrefix }} 

          - Bootstrap LB: {{ $.Values.kafka.name }}.{{ .Values.kafka.loadBalancer.domain}}
           {{- else }}
          - Bootstrap LB: {{ $.Values.kafka.loadBalancer.bootstrapPrefix }}.{{ .Values.kafka.loadBalancer.domain}}
          {{- end }}
      {{- range $i, $e :=  until (.Values.kafka.replicas | int) }}

          - Pod name: {{ $.Values.kafka.name }}-{{ $i }}
            {{- if empty $.Values.kafka.loadBalancer.brokerPrefix }}  
            DNS endpoints: b{{- $i }}.{{- $.Values.kafka.loadBalancer.domain }}
            {{- else }} 
            DNS endpoints: {{ $.Values.kafka.loadBalancer.brokerPrefix }}{{- $i }}.{{- $.Values.kafka.loadBalancer.domain }}
            {{- end }}
            {{ $.Values.global.provider.name | upper }} LB Endpoint: kubectl -n {{ $.Release.Namespace }} describe svc {{ $.Values.kafka.name }}-{{ $i }}-lb
       {{- end }}

        ***You can get all above information on the status field by running the below command**

        kubectl -n {{ .Release.Namespace }} get kafka {{ $.Values.kafka.name }}  -oyaml

            Create the DOMAIN: {{ .Values.kafka.loadBalancer.domain }} and update LB endpoint for each DNS endpoint for each broker as necessary.

        Install Confluent Cloud CLI: https://docs.confluent.io/current/quickstart/cloud-quickstart.html#step-2-install-ccloud-cli
        For CLI initialization: (https://docs.confluent.io/current/quickstart/cloud-quickstart.html#step-3-configure-ccloud-cli
      {{ end }}

      Internal:

        - Go to one of the Kafka Pods

          kubectl -n {{ $.Release.Namespace }} exec -it {{ $.Values.kafka.name }}-0 bash

        - Inside the pod, run below command

cat <<EOF > kafka.properties
## Copy information from kafka.properties available in step 7 (Client Access) step 1.
EOF
            + Check brokers API versions

              Get <bootstrapEndpoint> from step 2

              kafka-broker-api-versions --command-config kafka.properties --bootstrap-server <bootstrapEndpoint>

            + Run command to create topic

              Get <replicationFactor> from step 3
              Get <zookeeperConnect> from step 4

              kafka-topics --create --zookeeper <zookeeperConnect> --replication-factor <replicationFactor> --partitions 1 --topic example

              Note: Above command only works inside the kubernetes network

            + Run command to Publish events on topic example

              Get <bootstrapEndpoint> from step 2

              seq 10000 | kafka-console-producer --topic example --broker-list <bootstrapEndpoint> --producer.config kafka.properties

            + Run command to Consume events on topic example (run in different terminal)

              Get <bootstrapEndpoint> from step 2

              kafka-console-consumer --from-beginning --topic example --bootstrap-server  <bootstrapEndpoint> --consumer.config kafka.properties
{{- end }}

{{- if $.Values.controlcenter.enabled }}

      ControlCenter Deployment

ControlCenter is deployed through PSC

   0. List of Deprecated Features (if any)
      {{ include "confluent-operator.deprecated-list" .Values.controlcenter }}

   1. Validate if controlcenter is running

     kubectl get pods -n {{ .Release.Namespace }} | grep {{ $.Values.controlcenter.name }}

   2. Access

      {{- if .Values.controlcenter.loadBalancer.enabled }}
      {{- if .Values.controlcenter.tls.enabled }}

      External: https://{{ $.Values.controlcenter.loadBalancer.prefix | default $.Values.controlcenter.name }}.{{ $.Values.controlcenter.loadBalancer.domain }}:{{ .Values.controlcenter.tls.port }}
      {{- else }}
      External: http://{{ $.Values.controlcenter.loadBalancer.prefix | default $.Values.controlcenter.name }}.{{ $.Values.controlcenter.loadBalancer.domain }}:80
      {{- end }}
      {{- end }}
      
      {{- if .Values.controlcenter.tls.enabled }}
      Internal: https://{{ $.Values.controlcenter.name }}:9021 (Inside Kubernetes)
      Internal: http://{{ $.Values.controlcenter.name }}:8021 (Inside Kubernetes)
      {{- else }}
      Internal: http://{{ $.Values.controlcenter.name }}:9021 (Inside Kubernetes)
      {{- end }}
      
      Local Test:

        kubectl -n {{ .Release.Namespace }} port-forward {{ $.Values.controlcenter.name }}-0 12345:9021

        {{- if .Values.controlcenter.tls.enabled }}
        Open on browser: https://localhost:12345
        {{- else }}
        Open on browser: http://localhost:12345
        {{- end }}

   {{- if $.Values.controlcenter.auth.basic.enabled }}

   3. Authentication: Basic

   {{- end }}
   {{- if $.Values.controlcenter.auth.ldap.enabled }}

   3. Authentication: LDAP
   
   {{- end }}
{{- end }}

{{- if .Values.connect.enabled }}

       Connect Cluster Deployment

Connect Cluster is deployed through PSC. To configure connectors use ControlCenter or Use REST API to configure.
The Connect Cluster endpoint does not support authorization and must not be open for Internet Access.

  0. List of Deprecated Features (if any)
     {{ include "confluent-operator.deprecated-list" .Values.connect }}

  1. Validate if connect cluster is running

     kubectl get pods -n {{ .Release.Namespace }} | grep {{ $.Values.connect.name }}

  2. Access

  {{- if $.Values.connect.loadBalancer.enabled }}
  {{- if $.Values.connect.tls.enabled }}
     External REST Endpoint : https://{{ $.Values.connect.loadBalancer.prefix | default $.Values.connect.name }}.{{- $.Values.connect.loadBalancer.domain }}:{{ .Values.connect.tls.port }}
  {{- else }}
     External REST Endpoint : http://{{ $.Values.connect.loadBalancer.prefix | default $.Values.connect.name }}:80
  {{- end }}
  {{- end }}

     {{- if .Values.connect.tls.enabled }}
     Internal REST Endpoint : https://{{ $.Values.connect.name }}:8083 (Inside Kubernetes)
     Internal REST Endpoint : http://{{ $.Values.connect.name }}:9083 (Inside Kubernetes)

     OR

     http://localhost:9083 (Inside Pod)
     {{- else }}
     Internal REST Endpoint : http://{{ $.Values.connect.name }}:8083 (Inside Kubernetes)

     OR

     http://localhost:8083 (Inside Pod)
     {{- end }}

     More information can be found here: https://docs.confluent.io/current/connect/references/restapi.html

{{- end }}

{{- if .Values.replicator.enabled }}


       Replicator Connect Cluster Deployment

Replicator Connect Cluster is deployed through PSC. To configure replicator connector use REST API to configure.
The Replicator Connect Cluster endpoint does not support authorization and must not be open for Internet Access.

  0. List of Deprecated Features (if any)
     {{ include "confluent-operator.deprecated-list" .Values.replicator }}

  1. Validate if replicator cluster is running

     kubectl get pods -n {{ .Release.Namespace }} | grep {{ $.Values.replicator.name }}

  2. Access

  {{- if $.Values.replicator.loadBalancer.enabled }}
  {{- if $.Values.replicator.tls.enabled }}

    External REST Endpoint : https://{{ $.Values.replicator.loadBalancer.prefix | default $.Values.replicator.name }}.{{- $.Values.replicator.loadBalancer.domain }}:{{ .Values.replicator.tls.port }}
  {{- else }}
    External REST Endpoint : http://{{ $.Values.replicator.loadBalancer.prefix | default $.Values.replicator.name }}.{{- $.Values.replicator.loadBalancer.domain }}:80
  {{- end }}
  {{- end }}

    {{- if $.Values.replicator.tls.enabled }}
    Internal REST Endpoint : https://{{ $.Values.replicator.name }}:8083  (Inside kubernetes)
    Internal REST Endpoint : http://{{ $.Values.replicator.name }}:9083  (Inside kubernetes)

    OR

    http://localhost:9083 (Inside Pod)
    {{- else }}
    Internal REST Endpoint : http://{{ $.Values.replicator.name }}:8083  (Inside kubernetes)

    OR

    http://localhost:8083 (Inside Pod)
    {{- end }}
  
    More information about configuration example can be found here,

    https://github.com/confluentinc/cp-demo/blob/5.0.x/scripts/connectors/

{{- end }}

{{- if .Values.schemaregistry.enabled }}

Schema Registry is deployed through PSC. Configure Schema Registry through REST Endpoint

  0. List of Deprecated Features (if any)
     {{ include "confluent-operator.deprecated-list" .Values.schemaregistry }}

  1. Validate if schema registry cluster is running

     kubectl get pods -n {{ .Release.Namespace }} | grep {{ $.Values.schemaregistry.name }}

  2. Access

  {{- if .Values.schemaregistry.loadBalancer.enabled }} 
  {{- if .Values.schemaregistry.tls.enabled }}

    External REST Endpoint : https://{{ $.Values.schemaregistry.loadBalancer.prefix | default $.Values.schemaregistry.name }}.{{- $.Values.schemaregistry.loadBalancer.domain }}:{{ .Values.schemaregistry.tls.port }}
  {{- else }}
    External REST Endpoint : http://{{ $.Values.schemaregistry.loadBalancer.prefix | default $.Values.schemaregistry.name }}.{{- $.Values.schemaregistry.loadBalancer.domain }}:80
  {{- end }}
  {{- end }}

    {{- if .Values.schemaregistry.tls.enabled }}
    Internal REST Endpoint : https://{{ $.Values.schemaregistry.name }}:8081  (Inside kubernetes)
    Internal REST Endpoint : http://{{ $.Values.schemaregistry.name }}:9081  (Inside kubernetes)

    OR

    http://localhost:9081 (Inside Pod)
    {{- else }}
    Internal REST Endpoint : http://{{ $.Values.schemaregistry.name }}:8081  (Inside kubernetes)

    OR

    http://localhost:8081 (Inside Pod)
    {{- end }}

    More information about schema registry REST API can be found here,

    https://docs.confluent.io/current/schema-registry/docs/api.html


{{- end }}

{{- if $.Values.ksql.enabled }}

      KSQL Deployment

KSQL is deployed through PSC

   0. List of Deprecated Features (if any)
      {{ include "confluent-operator.deprecated-list" .Values.ksql }}

   1. Validate if ksql is running

     kubectl get pods -n {{ .Release.Namespace }} | grep {{ $.Values.ksql.name }}

   2. Access

      {{- if .Values.ksql.loadBalancer.enabled }}
      {{- if .Values.ksql.tls.enabled }}

      External: https://{{ $.Values.ksql.loadBalancer.prefix | default $.Values.ksql.name }}.{{ $.Values.ksql.loadBalancer.domain }}:{{ $.Values.ksql.tls.port }}
      {{- else }}
      External: http://{{ $.Values.ksql.loadBalancer.prefix | default $.Values.ksql.name }}.{{ $.Values.ksql.loadBalancer.domain }}:80

         Note: Create DNS entry and update LB as required. 
      {{- end }}
      {{- end }}

      {{- if .Values.ksql.tls.enabled }}
      Internal: https://{{ $.Values.ksql.name }}:8088 (Inside kubernetes)
      Internal: http://{{ $.Values.ksql.name }}:9088 (Inside kubernetes)

      OR

      http://localhost:9088 (Inside Pod)
      {{- else }}
      Internal: http://{{ $.Values.ksql.name }}:8088 (Inside kubernetes)

      OR

      http://localhost:8088 (Inside Pod)
      {{- end }}

{{- end }}

Note: For Openshift Platform replace kubectl commands with 'oc' commands. If OpenShift Route enabled, port will be either 80/443